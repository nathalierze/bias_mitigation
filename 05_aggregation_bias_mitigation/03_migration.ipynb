{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    log_loss,\n",
    "    roc_auc_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    accuracy_score,\n",
    "    plot_roc_curve,\n",
    "    plot_confusion_matrix,\n",
    "    roc_curve,\n",
    "    confusion_matrix,\n",
    ")\n",
    "import itertools\n",
    "from tensorflow.keras.initializers import Constant, TruncatedNormal\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numpy import mean, absolute"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation Bias Mitigation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 1: deutsch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define count of n from temporal models\n",
    "n = list(range(2, 61))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data per matrix\n",
    "for i in n:\n",
    "    path = \"../06_optimize_Fairness/eigSprache_allsessions/matrix\" + str(i) + \".pkl\"\n",
    "    infile = open(path, \"rb\")\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "    df = df[df.eigSprache == 1]\n",
    "\n",
    "    # save\n",
    "    path = \"erstsprache/matrix_deutsch\" + str(i) + \".pkl\"\n",
    "    df.to_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define metrics dataframe\n",
    "metrics = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"model\",\n",
    "        \"group\",\n",
    "        \"subgroup\",\n",
    "        \"Length\",\n",
    "        \"Sentence\",\n",
    "        \"Accuracy\",\n",
    "        \"Precision\",\n",
    "        \"Recall\",\n",
    "        \"AUC\",\n",
    "        \"FPR\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature cols\n",
    "feature_cols = [\n",
    "    \"Erstloesung\",\n",
    "    \"Schussel\",\n",
    "    \"Erfolg\",\n",
    "    \"Schwierigkeit\",\n",
    "    \"ist_Schulzeit\",\n",
    "    \"MehrfachFalsch\",\n",
    "    \"vorher_abgebrochen\",\n",
    "    \"Fehler\",\n",
    "    \"Klassenstufe\",\n",
    "    \"Jahredabei\",\n",
    "    \"Testposition__pruefung\",\n",
    "    \"Testposition__training\",\n",
    "    \"Testposition__version\",\n",
    "    \"Art__GK\",\n",
    "    \"Art__GR\",\n",
    "    \"Art__GZ\",\n",
    "    \"Art__K\",\n",
    "    \"Art__LB\",\n",
    "    \"UserAttribut\",\n",
    "    \"OrderNumber\",\n",
    "    \"steps\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "calculate and extract relevant metrics from y and pred\n",
    "return metrics\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_metrics(clf, X, y, cv, pred):\n",
    "    a = accuracy_score(y, pred)\n",
    "    p = precision_score(y, pred)\n",
    "    r = recall_score(y, pred)\n",
    "    roc_auc = roc_auc_score(y, pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, pred).ravel()\n",
    "    fpr = fp / (fp + tn)\n",
    "\n",
    "    return a, p, r, roc_auc, fpr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model fitting and validation\n",
    "\n",
    "# loop through matrices\n",
    "for i in n:\n",
    "    path = \"erstsprache/matrix_deutsch\" + str(i) + \".pkl\"\n",
    "    infile = open(path, \"rb\")\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "    df = df.reset_index()\n",
    "    X = df[feature_cols]\n",
    "    y = df.y\n",
    "    y = y.astype(\"int\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=1\n",
    "    )\n",
    "    k = 5\n",
    "    cv = KFold(n_splits=k, random_state=None)\n",
    "\n",
    "    # fit\n",
    "    clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "\n",
    "    a, p, r, roc_auc, fpr = get_metrics(clf, X_test, y_test, cv, pred)\n",
    "    metrics = metrics.append(\n",
    "        {\n",
    "            \"model\": \"DTE\",\n",
    "            \"group\": \"erstsprache\",\n",
    "            \"subgroup\": \"deutsch\",\n",
    "            \"Length\": len(df),\n",
    "            \"Sentence\": i,\n",
    "            \"Accuracy\": a,\n",
    "            \"Precision\": p,\n",
    "            \"Recall\": r,\n",
    "            \"AUC\": roc_auc,\n",
    "            \"FPR\": fpr,\n",
    "        },\n",
    "        ignore_index=True,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model fitting and validation\n",
    "\n",
    "# loop through matrices\n",
    "for i in n:\n",
    "    path = \"erstsprache/matrix_deutsch\" + str(i) + \".pkl\"\n",
    "    infile = open(path, \"rb\")\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "    df = df.reset_index()\n",
    "    X = df[feature_cols]\n",
    "    y = df.y\n",
    "    y = y.astype(\"int\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=1\n",
    "    )\n",
    "    k = 5\n",
    "    cv = KFold(n_splits=k, random_state=None)\n",
    "\n",
    "    # knn\n",
    "    knn = KNeighborsClassifier(n_neighbors=2)\n",
    "    knn = knn.fit(X_train, y_train)\n",
    "    pred = knn.predict(X_test)\n",
    "\n",
    "    a, p, r, roc_auc, fpr = get_metrics(knn, X_test, y_test, cv, pred)\n",
    "    metrics = metrics.append(\n",
    "        {\n",
    "            \"model\": \"KNN\",\n",
    "            \"group\": \"erstsprache\",\n",
    "            \"subgroup\": \"deutsch\",\n",
    "            \"Length\": len(df),\n",
    "            \"Sentence\": i,\n",
    "            \"Accuracy\": a,\n",
    "            \"Precision\": p,\n",
    "            \"Recall\": r,\n",
    "            \"AUC\": roc_auc,\n",
    "            \"FPR\": fpr,\n",
    "        },\n",
    "        ignore_index=True,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model fitting and validation\n",
    "\n",
    "\"\"\"\"\n",
    "build dropout prediction model\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(21, input_dim=21, activation=\"relu\"))\n",
    "    model.add(Dense(44, activation=\"relu\"))\n",
    "    model.add(Dense(22, activation=\"relu\"))\n",
    "    model.add(Dense(11, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "calculate and extract relevant metrics from y and pred\n",
    "return metrics\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_dn_metrics(model, X, y):\n",
    "    yhat_probs = model.predict(X, verbose=0)\n",
    "    yhat_classes = (model.predict(X) > 0.5).astype(\"int32\")\n",
    "    # reduce to 1d array\n",
    "    yhat_probs = yhat_probs[:, 0]\n",
    "    yhat_classes = yhat_classes[:, 0]\n",
    "    a = accuracy_score(y, yhat_classes)\n",
    "    p = precision_score(y, yhat_classes)\n",
    "    r = recall_score(y, yhat_classes)\n",
    "    roc_auc = roc_auc_score(y, yhat_probs)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, yhat_classes).ravel()\n",
    "    fpr = fp / (fp + tn)\n",
    "\n",
    "    return a, p, r, roc_auc, fpr\n",
    "\n",
    "\n",
    "# loop through matrices\n",
    "for i in n:\n",
    "    path = \"erstsprache/matrix_deutsch\" + str(i) + \".pkl\"\n",
    "    infile = open(path, \"rb\")\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "    df = df.reset_index()\n",
    "\n",
    "    y_len = len(feature_cols)\n",
    "    X = df[feature_cols].astype(float)\n",
    "    y = df.y\n",
    "    y = y.astype(\"int\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=1\n",
    "    )\n",
    "\n",
    "    model = build_model()\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        epochs=10,\n",
    "        batch_size=128,\n",
    "        verbose=0,\n",
    "        validation_data=(X_test, y_test),\n",
    "    )\n",
    "\n",
    "    scores = model.evaluate(x=X_test, y=y_test, verbose=0)\n",
    "\n",
    "    a, p, r, roc_auc, fpr = get_dn_metrics(model, X_test, y_test)\n",
    "    metrics = metrics.append(\n",
    "        {\n",
    "            \"model\": \"DL\",\n",
    "            \"group\": \"erstsprache\",\n",
    "            \"subgroup\": \"deutsch\",\n",
    "            \"Length\": len(df),\n",
    "            \"Sentence\": i,\n",
    "            \"Accuracy\": a,\n",
    "            \"Precision\": p,\n",
    "            \"Recall\": r,\n",
    "            \"AUC\": roc_auc,\n",
    "            \"FPR\": fpr,\n",
    "        },\n",
    "        ignore_index=True,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 2: migration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data\n",
    "for i in n:\n",
    "    path = \"../06_optimize_Fairness/eigSprache_allsessions/matrix\" + str(i) + \".pkl\"\n",
    "    infile = open(path, \"rb\")\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "    df = df[df.eigSprache == 0]\n",
    "    # save\n",
    "    path = \"erstsprache/matrix_migration\" + str(i) + \".pkl\"\n",
    "    df.to_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define feature cols\n",
    "feature_cols = [\n",
    "    \"Erstloesung\",\n",
    "    \"Schussel\",\n",
    "    \"Erfolg\",\n",
    "    \"Schwierigkeit\",\n",
    "    \"ist_Schulzeit\",\n",
    "    \"MehrfachFalsch\",\n",
    "    \"vorher_abgebrochen\",\n",
    "    \"Fehler\",\n",
    "    \"Klassenstufe\",\n",
    "    \"Jahredabei\",\n",
    "    \"Testposition__pruefung\",\n",
    "    \"Testposition__training\",\n",
    "    \"Testposition__version\",\n",
    "    \"Art__GK\",\n",
    "    \"Art__GR\",\n",
    "    \"Art__GZ\",\n",
    "    \"Art__K\",\n",
    "    \"Art__LB\",\n",
    "    \"UserAttribut\",\n",
    "    \"OrderNumber\",\n",
    "    \"steps\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model fitting and validation\n",
    "\n",
    "# loop through matrices\n",
    "for i in n:\n",
    "    path = \"erstsprache/matrix_migration\" + str(i) + \".pkl\"\n",
    "    infile = open(path, \"rb\")\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "    df = df.reset_index()\n",
    "    X = df[feature_cols]\n",
    "    y = df.y\n",
    "    y = y.astype(\"int\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=1\n",
    "    )\n",
    "    k = 5\n",
    "    cv = KFold(n_splits=k, random_state=None)\n",
    "\n",
    "    # fit\n",
    "    clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "\n",
    "    a, p, r, roc_auc, fpr = get_metrics(clf, X_test, y_test, cv, pred)\n",
    "    metrics = metrics.append(\n",
    "        {\n",
    "            \"model\": \"DTE\",\n",
    "            \"group\": \"erstsprache\",\n",
    "            \"subgroup\": \"migration\",\n",
    "            \"Length\": len(df),\n",
    "            \"Sentence\": i,\n",
    "            \"Accuracy\": a,\n",
    "            \"Precision\": p,\n",
    "            \"Recall\": r,\n",
    "            \"AUC\": roc_auc,\n",
    "            \"FPR\": fpr,\n",
    "        },\n",
    "        ignore_index=True,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model fitting and validation\n",
    "\n",
    "# loop through matrices\n",
    "for i in n:\n",
    "    # build models\n",
    "    path = \"erstsprache/matrix_migration\" + str(i) + \".pkl\"\n",
    "    infile = open(path, \"rb\")\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "    df = df.reset_index()\n",
    "    X = df[feature_cols]\n",
    "    y = df.y\n",
    "    y = y.astype(\"int\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=1\n",
    "    )\n",
    "    k = 5\n",
    "    cv = KFold(n_splits=k, random_state=None)\n",
    "\n",
    "    # fit\n",
    "    knn = KNeighborsClassifier(n_neighbors=2)\n",
    "    knn = knn.fit(X_train, y_train)\n",
    "    pred = knn.predict(X_test)\n",
    "\n",
    "    a, p, r, roc_auc, fpr = get_metrics(knn, X_test, y_test, cv, pred)\n",
    "    metrics = metrics.append(\n",
    "        {\n",
    "            \"model\": \"KNN\",\n",
    "            \"group\": \"erstsprache\",\n",
    "            \"subgroup\": \"migration\",\n",
    "            \"Length\": len(df),\n",
    "            \"Sentence\": i,\n",
    "            \"Accuracy\": a,\n",
    "            \"Precision\": p,\n",
    "            \"Recall\": r,\n",
    "            \"AUC\": roc_auc,\n",
    "            \"FPR\": fpr,\n",
    "        },\n",
    "        ignore_index=True,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model fitting and validation\n",
    "\n",
    "\"\"\"\"\n",
    "build dropout prediction model\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(21, input_dim=21, activation=\"relu\"))\n",
    "    model.add(Dense(44, activation=\"relu\"))\n",
    "    model.add(Dense(22, activation=\"relu\"))\n",
    "    model.add(Dense(11, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "calculate and extract relevant metrics from y and pred\n",
    "return metrics\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_dn_metrics(model, X, y):\n",
    "    yhat_probs = model.predict(X, verbose=0)\n",
    "    yhat_classes = (model.predict(X) > 0.5).astype(\"int32\")\n",
    "    # reduce to 1d array\n",
    "    yhat_probs = yhat_probs[:, 0]\n",
    "    yhat_classes = yhat_classes[:, 0]\n",
    "    a = accuracy_score(y, yhat_classes)\n",
    "    p = precision_score(y, yhat_classes)\n",
    "    r = recall_score(y, yhat_classes)\n",
    "    roc_auc = roc_auc_score(y, yhat_probs)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, yhat_classes).ravel()\n",
    "    fpr = fp / (fp + tn)\n",
    "\n",
    "    return a, p, r, roc_auc, fpr\n",
    "\n",
    "\n",
    "# loop through matrices\n",
    "for i in n:\n",
    "    path = \"erstsprache/matrix_migration\" + str(i) + \".pkl\"\n",
    "    infile = open(path, \"rb\")\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "    df = df.reset_index()\n",
    "\n",
    "    y_len = len(feature_cols)\n",
    "    X = df[feature_cols].astype(float)\n",
    "    y = df.y\n",
    "    y = y.astype(\"int\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=1\n",
    "    )\n",
    "\n",
    "    model = build_model()\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        epochs=10,\n",
    "        batch_size=128,\n",
    "        verbose=0,\n",
    "        validation_data=(X_test, y_test),\n",
    "    )\n",
    "\n",
    "    scores = model.evaluate(x=X_test, y=y_test, verbose=0)\n",
    "\n",
    "    a, p, r, roc_auc, fpr = get_dn_metrics(model, X_test, y_test)\n",
    "    metrics = metrics.append(\n",
    "        {\n",
    "            \"model\": \"DL\",\n",
    "            \"group\": \"erstsprache\",\n",
    "            \"subgroup\": \"migration\",\n",
    "            \"Length\": len(df),\n",
    "            \"Sentence\": i,\n",
    "            \"Accuracy\": a,\n",
    "            \"Precision\": p,\n",
    "            \"Recall\": r,\n",
    "            \"AUC\": roc_auc,\n",
    "            \"FPR\": fpr,\n",
    "        },\n",
    "        ignore_index=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot count of sentences by n and subgroup\n",
    "ax = sns.lineplot(data=metrics, x=\"Sentence\", y=\"Length\", hue=\"subgroup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## construct dfs for both groups from metric df\n",
    "grouped = metrics.groupby(metrics.subgroup)\n",
    "df_deutsch = grouped.get_group(\"deutsch\")\n",
    "df_migration = grouped.get_group(\"migration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot accuracy by n and model\n",
    "ax = sns.lineplot(data=df_deutsch, x=\"Sentence\", y=\"Accuracy\", hue=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot accuracy by n and model\n",
    "ax = sns.lineplot(data=df_migration, x=\"Sentence\", y=\"Accuracy\", hue=\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = metrics.groupby(df.group)\n",
    "df_erstsprache = grouped.get_group(\"erstsprache\")\n",
    "# calculate fairness metrics\n",
    "df_erstsprache = df_erstsprache.drop(columns=[\"group\", \"Accuracy\"])\n",
    "df_erstsprache = pd.pivot_table(\n",
    "    df_erstsprache,\n",
    "    values=[\"Precision\", \"Recall\", \"AUC\", \"FPR\"],\n",
    "    index=[\"model\", \"Sentence\"],\n",
    "    columns=[\"subgroup\"],\n",
    ")\n",
    "df_erstsprache[\"PP\"] = (\n",
    "    df_erstsprache.Precision.deutsch - df_erstsprache.Precision.migration\n",
    ")\n",
    "df_erstsprache[\"EO\"] = df_erstsprache.Recall.migration - df_erstsprache.Recall.deutsch\n",
    "df_erstsprache[\"SA\"] = df_erstsprache.AUC.deutsch - df_erstsprache.AUC.migration\n",
    "df_erstsprache[\"PE\"] = df_erstsprache.FPR.migration - df_erstsprache.FPR.deutsch\n",
    "df_erstsprache = df_erstsprache.drop(columns=[\"AUC\", \"Precision\", \"Recall\", \"FPR\"])\n",
    "df_erstsprache.columns = df_erstsprache.columns.droplevel(1)\n",
    "df_erstsprache = pd.pivot_table(\n",
    "    df_erstsprache,\n",
    "    values=[\"PP\", \"EO\", \"SA\", \"PE\"],\n",
    "    index=[\"Sentence\"],\n",
    "    columns=[\"model\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "functions to format results\n",
    "set two threshols: one at |0.02| in orange and one at |0.05| in red\n",
    "format all negative values in bold\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def threshold001(v, props=\"\"):\n",
    "    return props if (v > 0.02) or (v < -0.02) else None\n",
    "\n",
    "\n",
    "def threshold005(v, props=\"\"):\n",
    "    return props if (v > 0.05) or (v < -0.05) else None\n",
    "\n",
    "\n",
    "def negativeValue(v, props=\"\"):\n",
    "    return props if (v < 0) else None\n",
    "\n",
    "\n",
    "def showTable(df):\n",
    "    styled = (\n",
    "        df.style.set_properties(color=\"black\", align=\"right\")\n",
    "        .set_properties(**{\"background-color\": \"white\"})\n",
    "        .applymap(threshold001, props=\"color:orange;\")\n",
    "        .applymap(threshold005, props=\"color:red;\")\n",
    "        .applymap(negativeValue, props=\"font-weight:bold;\")\n",
    "    )\n",
    "    return styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = showTable(df_erstsprache)\n",
    "# s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a table that is readable\n",
    "# take the mean from ten sentences as one cell\n",
    "\n",
    "met = [\"EO\", \"PE\", \"PP\", \"SA\"]\n",
    "model = [\"DL\", \"DTE\", \"KNN\"]\n",
    "ranges = [\n",
    "    (\"02-9\", 8),\n",
    "    (\"10-19\", 9),\n",
    "    (\"20-29\", 9),\n",
    "    (\"30-39\", 9),\n",
    "    (\"40-49\", 9),\n",
    "    (\"50-60\", 10),\n",
    "]\n",
    "\n",
    "frame_means = pd.DataFrame()\n",
    "\n",
    "# for each metric\n",
    "for m in met:\n",
    "    for mo in model:\n",
    "        for r, div in ranges:\n",
    "            s = 0\n",
    "            for i in range(int(r[:2]), int(r[-2:]) + 1):\n",
    "                s += df_erstsprache[m][mo][i]\n",
    "            temp = pd.DataFrame(\n",
    "                {\"Metrik\": [m], \"Model\": mo, \"Range\": r, \"Val\": s / div}\n",
    "            )\n",
    "            frame_means = pd.concat([frame_means, temp])\n",
    "\n",
    "# pivot table\n",
    "mean_table = pd.pivot_table(\n",
    "    frame_means, values=[\"Val\"], index=[\"Range\"], columns=[\"Metrik\", \"Model\"]\n",
    ")\n",
    "showTable(mean_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "writer = pd.ExcelWriter(\"df_erstsprache_AggBias.xlsx\", engine=\"xlsxwriter\")\n",
    "df_erstsprache.to_excel(writer, sheet_name=\"erstsprache\")\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
