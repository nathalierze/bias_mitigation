{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, roc_auc_score, recall_score, precision_score, accuracy_score, plot_roc_curve, plot_confusion_matrix, roc_curve, confusion_matrix\n",
    "import itertools\n",
    "from tensorflow.keras.initializers import Constant, TruncatedNormal\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numpy import mean, absolute\n",
    "\n",
    "# Oversampling and under sampling\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from collections import Counter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Bias Mitigation: Migration Background <> DTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define count of n from temporal models\n",
    "n = list(range(2, 61))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load survey data\n",
    "infile = open('../../02_dropout_prediction/01_keep_it_up/fairness_ready.pkl','rb')\n",
    "df_survey = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "df_survey = df_survey[['UebungsID','eigSprache']]\n",
    "df_survey = df_survey.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data\n",
    "# not balanced out, as representational bias is not attempted to be mitigated yet\n",
    "for i in n:\n",
    "    path='../../02_dropout_prediction/01_keep_it_up/matrices_allsessions/matrix'+str(i)+'.pkl'\n",
    "    infile = open(path,'rb')\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "    df = df.reset_index(level=0)\n",
    "    df = pd.merge(df, df_survey, how='left')\n",
    "\n",
    "    df_1 = df[df.eigSprache==1]\n",
    "    df_0 = df[df.eigSprache==0]\n",
    "    df = pd.concat([df_0,df_1])\n",
    "\n",
    "    # Randomly over sample the minority class\n",
    "    X_df = df.drop(columns=['eigSprache'])\n",
    "    y_df = df.eigSprache\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote= smote.fit_resample(X_df, y_df)\n",
    "    df = X_train_smote.join(pd.DataFrame(list(y_train_smote.values), columns=['eigSprache']))\n",
    "    \n",
    "    # save\n",
    "    path = 'eigSprache_allsessions/matrix'+ str(i) +'.pkl'\n",
    "    df.to_pickle(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define metrics dataframe\n",
    "metrics = pd.DataFrame(columns=['model', 'group', 'subgroup','Length', 'Sentence', 'Accuracy','max_depth', 'min_samples_leaf', 'min_samples_split', 'Precision', 'Recall', 'AUC', 'FPR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define feature cols\n",
    "feature_cols = ['Erstloesung','Schussel','Erfolg', 'Schwierigkeit', 'ist_Schulzeit', 'MehrfachFalsch', 'vorher_abgebrochen','Fehler', 'Klassenstufe', 'Jahredabei', 'AnzahlAufgaben', 'Sex__m', 'Sex__w', 'Testposition__pruefung', 'Testposition__training','Testposition__version', 'Art__GK', 'Art__GR', 'Art__GZ', 'Art__K', 'Art__LB','UserAttribut', 'OrderNumber', 'steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "calculate and extract relevant metrics from y and pred\n",
    "return metrics\n",
    "\"\"\"\n",
    "def get_metrics(clf,X,y,cv,pred):\n",
    "    a = accuracy_score(y,pred)\n",
    "    p = precision_score(y,pred)\n",
    "    r = recall_score(y,pred)\n",
    "\n",
    "    roc_auc = roc_auc_score(y,pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, pred).ravel()\n",
    "    fpr = fp/(fp+tn)\n",
    "\n",
    "    return a,p,r,roc_auc,fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [1,5,10,15,20,25,5,5,5,5,5,5,5,5,5,5,5,5]\n",
    "min_samples_leaf = [1,1,1,1,1,1,1,5,10,15,20,25,1,1,1,1,1,1]\n",
    "min_samples_split = [2,2,2,2,2,2,2,2,2,2,2,2,2,5,10,15,20,25]\n",
    "\n",
    "## build model for different parameters\n",
    "for (max_depth, min_samples_leaf, min_samples_split) in zip(max_depth, min_samples_leaf, min_samples_split):\n",
    "    for i in n:\n",
    "        path='eigSprache_allsessions/matrix'+str(i)+'.pkl'\n",
    "        infile = open(path,'rb')\n",
    "        df = pickle.load(infile)\n",
    "        infile.close()\n",
    "        df=df.reset_index()\n",
    "        X = df[feature_cols]\n",
    "        y = df.y\n",
    "        y= y.astype('int')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "        k = 5\n",
    "        cv = KFold(n_splits=k, random_state=None)\n",
    "\n",
    "        # fit\n",
    "        clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=max_depth,min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split)\n",
    "        clf = clf.fit(X_train,y_train)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        a,p,r,roc_auc,fpr = get_metrics(clf,X_test,y_test,cv,pred)\n",
    "        metrics = metrics.append({'model':'DTE','group':'all','subgroup':'all','Length':len(df),'Sentence': i, 'Accuracy':a,'max_depth':max_depth, 'min_samples_leaf':min_samples_leaf, 'min_samples_split':min_samples_split,'Precision': p, 'Recall':r, 'AUC':roc_auc, 'FPR':fpr}, ignore_index=True)\n",
    "\n",
    "        group = ['eigSprache', 'eigSprache']\n",
    "        subgroup = ['deutsch', 'migration']\n",
    "        matrice = ['matrices_forte_deutsch', 'matrices_forte_migration']\n",
    "\n",
    "        for (group, subgroup, matrix) in zip(group, subgroup, matrice):\n",
    "            path= '../../02_dropout_prediction/01_keep_it_up/'+matrix+'/matrix'+str(i)+'.pkl'\n",
    "            infile = open(path,'rb')\n",
    "            df = pickle.load(infile)\n",
    "            infile.close()\n",
    "            df=df.reset_index()\n",
    "            X = df[feature_cols]\n",
    "            y = df.y\n",
    "            y= y.astype('int')\n",
    "            pred = clf.predict(X)\n",
    "            \n",
    "            a,p,r,roc_auc,fpr = get_metrics(clf,X,y,cv,pred)\n",
    "            metrics = metrics.append({'model':'DTE','group':group,'subgroup':subgroup,'Length':len(df),'Sentence': i, 'Accuracy':a,'max_depth':max_depth, 'min_samples_leaf':min_samples_leaf, 'min_samples_split':min_samples_split,'Precision': p, 'Recall':r, 'AUC':roc_auc, 'FPR':fpr}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## construct dfs from metric df\n",
    "grouped = metrics.groupby(df.group)\n",
    "df_eigSprache = grouped.get_group(\"eigSprache\")\n",
    "\n",
    "df_eigSprache = df_eigSprache.drop(columns=['group', 'Accuracy'])\n",
    "df_eigSprache = pd.pivot_table(df_eigSprache, values=[\"Precision\",\"Recall\",\"AUC\",\"FPR\"], index=['max_depth', 'min_samples_leaf', 'min_samples_split', \"Sentence\"], columns=[\"subgroup\"])\n",
    "df_eigSprache['PP'] = df_eigSprache.Precision.deutsch-df_eigSprache.Precision.migration\n",
    "df_eigSprache['EO'] = df_eigSprache.Recall.migration-df_eigSprache.Recall.deutsch\n",
    "df_eigSprache['SA'] = df_eigSprache.AUC.deutsch-df_eigSprache.AUC.migration\n",
    "df_eigSprache['PE'] = df_eigSprache.FPR.migration-df_eigSprache.FPR.deutsch\n",
    "df_eigSprache = df_eigSprache.drop(columns=['AUC','Precision','Recall','FPR'])\n",
    "df_eigSprache.columns = df_eigSprache.columns.droplevel(1)\n",
    "df_eigSprache = pd.pivot_table(df_eigSprache, values=[\"PP\",\"EO\",\"SA\",\"PE\"], index=[\"Sentence\"], columns=['max_depth', 'min_samples_leaf', 'min_samples_split'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "## create mean of results and map tp data frame\n",
    "met = ['EO', 'PE', 'PP', 'SA']\n",
    "index_ranges = [(2, 10, '02-9'), (10, 20, '10-19'), (20, 30, '20-29'),\n",
    "                (30, 40, '30-39'), (40, 50, '40-49'), (50, 60, '50-60')]\n",
    "param_ranges = {\n",
    "    'max_depth': [1, 5, 10, 15, 20, 25, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
    "    'min_samples_leaf': [1, 1, 1, 1, 1, 1, 1, 5, 10, 15, 20, 25, 1, 1, 1, 1, 1, 1],\n",
    "    'min_samples_split': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 10, 15, 20, 25]\n",
    "}\n",
    "\n",
    "data_list = []\n",
    "for (x, (i_start, i_end, i_range), params) in product(met, index_ranges, product(*param_ranges.values())):\n",
    "    indices = np.arange(i_start, i_end)\n",
    "    val = np.mean([df_eigSprache[x][p1][p2][p3][i] for (p1, p2, p3) in zip(*param_ranges.values()) for i in indices])\n",
    "    data = {'Metrik': [x],\n",
    "            'Model': 'DTE',\n",
    "            'Range': i_range,\n",
    "            'Val': val,\n",
    "            'max_depth': params[0],\n",
    "            'min_samples_leaf': params[1],\n",
    "            'min_samples_split': params[2]}\n",
    "    data_list.append(data)\n",
    "\n",
    "fertig = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "functions to format results\n",
    "set two threshols: one at |0.02| in orange and one at |0.05| in red\n",
    "format all negative values in bold\n",
    "\"\"\"\n",
    "def threshold001(v, props=''):\n",
    "    return props if (v > 0.02) or (v < -0.02) else None\n",
    "\n",
    "def threshold005(v, props=''):\n",
    "    return props if (v > 0.05) or (v < -0.05) else None\n",
    "\n",
    "def negativeValue(v, props=''):\n",
    "    return props if (v < 0) else None\n",
    "\n",
    "def showTable(df):\n",
    "    styled = df.style.set_properties(color=\"black\", align=\"right\")\\\n",
    "        .set_properties(**{'background-color': 'white'})\\\n",
    "        .applymap(threshold001, props='color:orange;')\\\n",
    "        .applymap(threshold005, props='color:red;')\\\n",
    "        .applymap(negativeValue, props='font-weight:bold;')\n",
    "    return styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show results table\n",
    "mean_table = pd.pivot_table(fertig, values=['Val'], index=['max_depth', 'min_samples_leaf', 'min_samples_split','Range'], columns=['Metrik','Model'])\n",
    "showTable(mean_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code to print results of specific measures\n",
    "\n",
    "# grouped = metrics.groupby(metrics.group)\n",
    "# df_all = grouped.get_group(\"all\")\n",
    "# modell = df_all.groupby(df_all.max_depth)\n",
    "# five = modell.get_group(5)\n",
    "# n = five.groupby(five.min_samples_leaf)\n",
    "# n = n.get_group(25)\n",
    "# f = n.groupby(n.min_samples_split)\n",
    "# f = f.get_group(2)\n",
    "# ax = sns.lineplot(data=f, x='Sentence', y='Accuracy', hue='model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
