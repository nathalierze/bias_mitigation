Bias Mitigation

Algorithms and machine learning models are increasingly used in educational settings. However, those approaches raise concerns about the potential for discrimination against demographic groups. 
While algorithmic fairness is often evaluated, existing research is lacking in two dimensions: 
-First, studies often focus on demographic features such as gender or race and ignore less-studied groups. 
-Second, many studies find algorithmic bias in educational models, but there is little research on how to mitigate it. 
In this work, we evaluate three drop-out prediction models that are applied in an online learning platform to acquire German spelling skills. 
We assess fairness for (in part) less-studied demographic groups: first spoken language, home literacy environment, parental education background and gender. 
To evaluate the models, we use four different fairness metrics and compare their results respectively: predictive parity, equalized odds, predictive equality and ABROCA. 
In addition, we present ways to mitigate algorithmic bias in models by examining the model at each point in the machine learning lifecycle. 
We find that bias existed in all models and impacted fairness of all four groups to different degrees. Furthermore, our results show that most biases can be mitigated during the process. 
However, how fairness is improved differs by demographic group. Moreover, some attempts to mitigate bias can lead to an improvement in one demographic group, while in others, discrimination is increased. 
We therefore conclude that reducing algorithmic bias is possible for less-studied demographic groups, but that it is important to find the right method for the specific algorithm and demographic group.

A detailed decription of the dropout prediction model is described here:
N. Rzepka, K. Simbeck, H.-G. Müller, and N. Pinkwart
Keep It Up: In-session Dropout Prediction to Support Blended Classroom Scenarios
Proceedings of the 14th International Conference on Computer Supported Education - Volume 2: CSEDU,, SciTePress, 2022, ISBN 978-989-758-562-3 

A publication about the fairness evaluation in detail can be found here:
N. Rzepka, K. Simbeck, H.-G. Müller, and N. Pinkwart
Fairness of In-session Dropout Prediction
Proceedings of the 14th International Conference on Computer Supported Education - Volume 2: CSEDU,, SciTePress, 2022, ISBN 978-989-758-562-3 

An sample data set as well as a metadata schema can be found here:
tba

This project is described in detail here:
tba

