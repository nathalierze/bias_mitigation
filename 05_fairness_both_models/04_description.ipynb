{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beschreibung der verwendeten Daten - Modell 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Welche Daten sind die Grundlage\n",
    "\n",
    "Daten von Orthografietrainer aus dem Jahr 2020\n",
    "Umfrage wurde von Usern freiwillig beantwortet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Wie wurde gefiltert und preprocessed\n",
    "        Datei: 15_FORTEdata.ipynb\n",
    "\n",
    "Zur Umfrage wurde gemerged: \n",
    "Sitzungsummary 2020\n",
    "    drop NA\n",
    "Alle Sätze\n",
    "Schueler 2020\n",
    "    nur Klassenstufen 5-12\n",
    "XMLsaetze\n",
    "\n",
    "Anzahl unique User in gemergdem Dataset: 4600\n",
    "\n",
    "Weitere Filter\n",
    "    Testposition: Version, pruefung, training\n",
    "    Monate: März, April, Mai, Juni\n",
    "\n",
    "Dann wurde ein komplizierter Code angewandt, um die Sitzungen in Sessions zu unterteilen. Bei 45 Minuten Inaktivität zwischen zwei Aufgaben handelt es sich um eine neue Session.\n",
    "Außerdem wurde one-hot encoding durchgeführt.\n",
    "\n",
    "Rauskommt die Datei: fairness_ready.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Wie werden die Evaluationsgruppen vorbereitet\n",
    "        Datei: 16_forte_subgroups.ipynb\n",
    "\n",
    "Bildung der Subgruppen\n",
    "    Abi Eltern\n",
    "    Gender\n",
    "    Migration\n",
    "    Anzahl Bücher\n",
    "\n",
    "Bildung der Matrizen für jede Subgruppe\n",
    "    n = [2,60]\n",
    "\n",
    "Deskriptive Statistik und Abbildung in 16_forte_subgroups\n",
    "    Anzahl User pro Subgruppe\n",
    "    Anzahl Uebungen pro n und Usergruppe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Wie wurden die Daten für das Predictionmodell vorbereitet\n",
    "        Datei: 16_FORTEmatrices\n",
    "\n",
    "Gruppierung der Daten nach UebungsID\n",
    "Datenset wird ausbalanciert (Abbruch 1/0)\n",
    "Datenset besteht dann aus \n",
    "    7528 Items pro y\n",
    "    15056 Uebungen (unique)\n",
    "    2496 User IDs (unique)\n",
    "\n",
    "Es werden dann pro Satznummer n Matrizen gebaut\n",
    "Abbildung zur Anzahl Matrizen pro n in Datei "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Wie wurde das Predictionmodell gebaut\n",
    "        Datei: 17_forte_models\n",
    "\n",
    "Modelle\n",
    "    DTE\n",
    "    Logistic Regression\n",
    "    KNN\n",
    "    SVM\n",
    "    DL\n",
    "\n",
    "Für alle n wurde ein Modell gefittet (ohne CV) und die Predictions gespeichert.\n",
    "\n",
    "Dann wurde für jede Subgruppe und n nochmals das Modell predicted und gespeichert. Es wurden die kompletten Subgruppen genutzt, um mehr zu haben. Das bedeutet, dass Teile der Trainingsdaten auch in den Subgruppen-Testdaten enthalten sind. Die Auswirkungen davon wurden geprüft und haben keinen Einfluss auf das Modell. Ein Code-Teil für die Modelle ohne die Trainingsdaten ist in 17_forte_models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Wie wurde die Fairness evaluiert\n",
    "        Datei: 18_forte_fairness\n",
    "\n",
    "Die Metriken aus der Prediction werden eingelesen. Die Tabelle wird nach Subgruppen grupiert, pivotiert und pro Subgruppe werden PP, EO, SA, PE berechnet. Das Ergebnis wird in einer Excel Tabelle gespeichert. In der Datei fairness_061021.xlsx werden die durchschnittlichen Ergebnisse pro 10 n erfasst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beschreibung der verwendeten Daten - Modell 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Welche Daten sind die Grundlage für das Predictionmodell\n",
    "\n",
    "Daten von Orthografietrainer aus dem Jahr 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Wie wurde gefiltert und preprocessed\n",
    "        Datei: 01_preprocessing.ipynb\n",
    "\n",
    "Schueler 2020\n",
    "    nur Klassenstufen 5-12\n",
    "Sitzungsummary\n",
    "    Userattribut: nur Schueler\n",
    "    Art: nur GK\n",
    "Alle Sätze\n",
    "    Art: nur GK\n",
    "    Aufgaben ID: alle außer 0 (0=Kompetenztests)\n",
    "XMLsaetze\n",
    "\n",
    "Alles one-hot encoded und gemerged.\n",
    "Rauskommt Zwischenschritt: final_data_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Wie wurde das Predictionmodell vorbereitet\n",
    "    Datei: 02_small_learningHistory3months.ipynb\n",
    "\n",
    "Dataset (final_data_preprocessed) wird ausbalanciert: pro y (1/0) 100.000 Items\n",
    "\n",
    "Komplizierter Code wird ausgeführt, der diesem Dataset eine Learning History hinzugibt. Es werden die letzten drei Monate seit dem letzten Login betrachtet: alles was der User hier ausgeführt hat, kommt in die Learning History.\n",
    "\n",
    "Am Ende werde duplicate entfernt.\n",
    "\n",
    "Fertig vorbearbeitete Datei: FINALsmallSampleSet_3months_without_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Wie wurde das Predictionmodell ausgeführt\n",
    "    Datei: 02_decisionTree_3months.ipynb\n",
    "\n",
    "Dataset wird in Trainings- und Testset gesplittet. CV mit k = 5. Scores werden gespeichert. \n",
    "\n",
    "Modelle\n",
    "    DTE\n",
    "    Logistic Regression\n",
    "    SVM\n",
    "    DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Wie wurde die Fairness Evaluation vorbereitet\n",
    "    Datei: 01_forte_data.ipynb\n",
    "\n",
    "Umfrage 2020\n",
    "Final_data_preprocessed -> Datensatz von Zwischenschritt s.o.\n",
    "Satze\n",
    "    Art = nur GK\n",
    "    AufgabenID = alles, außer 0 (weil 0=Kompetenztests)\n",
    "XMLsaetze\n",
    "\n",
    "Komplizierter Code zur Lernhistorie kommt dazu, nur letzte drei Monate werde betrachtet\n",
    "\n",
    "Zwischenergebnis ist das File: preprocessed_umfrage\n",
    "\n",
    "Dann wurden die Subgruppen gebildet:\n",
    "    Abi Eltern\n",
    "    Gender\n",
    "    Migration\n",
    "    Anzahl Bücher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Wie wurden die Evaluation durchgeführt\n",
    "        Datei: 02_models.ipynb\n",
    "        \n",
    "Das Predictionmodell wird importiert\n",
    "Dann wird jede Sugruppe importiert und getestet. \n",
    "Metriken werden gespeichert.\n",
    "\n",
    "Modelle:\n",
    "    DTE\n",
    "    Logistic Regression\n",
    "    SVM\n",
    "    NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Wie wurden Evaluation ausgewertet\n",
    "        Datei: 03_evaluation.ipynb\n",
    "\n",
    "Die Metriken aus der Prediction werden eingelesen. Die Tabelle wird nach Subgruppen grupiert, pivotiert und pro Subgruppe werden PP, EO, SA, PE berechnet. Das Ergebnis wird in einer Excel Tabelle gespeichert. In der Datei fairness_double.xlsx werden die durchschnittlichen Ergebnisse pro 10 n erfasst."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
