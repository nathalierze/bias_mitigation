{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold , cross_val_score\n",
    "from sklearn import metrics \n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "import openpyxl\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import log_loss, roc_auc_score, recall_score, precision_score, accuracy_score, plot_roc_curve, plot_confusion_matrix, roc_curve, confusion_matrix\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import log_loss, roc_auc_score, recall_score, precision_score, average_precision_score, f1_score, classification_report, accuracy_score, plot_roc_curve, plot_precision_recall_curve, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infile = open('../04_predictionUserHistory/02_decisionTree/X_train_3months.pkl', 'rb')\n",
    "# trainX = pickle.load(infile)\n",
    "# infile.close()\n",
    "\n",
    "# # Import feature list\n",
    "# infile = open('../04_predictionUserHistory/01_data/FINALsmallSampleSet_3months_without_duplicates.pkl','rb')\n",
    "# import_file = pickle.load(infile)\n",
    "# infile.close()\n",
    "# df = import_file\n",
    "# feature_cols = list(df.columns)\n",
    "\n",
    "# # list subgroups\n",
    "# fair_metrics = pd.DataFrame(columns=['model', 'group', 'subgroup', 'Accuracy', 'Precision', 'Recall', 'AUC', 'FPR'])\n",
    "# matrice = ['double_df_abi','double_df_keinAbi','double_df_boys','double_df_girls','double_df_deutsch','double_df_migration','double_df_buch0','double_df_buch1']\n",
    "# group = ['abiEltern', 'abiEltern', 'gender', 'gender', 'erstsprache', 'erstsprache', 'buecher', 'buecher']\n",
    "# subgroup = ['abi', 'keinAbi', 'boys', 'girls', 'deutsch', 'migration', 'buch0', 'buch1']\n",
    "\n",
    "# fails = pd.DataFrame(columns=['group', 'group_len', 'removed_duplicates', 'merge_with_train', 'remove_duplicates', 'exploited_rows'])\n",
    "\n",
    "# for (group, subgroup, matrice) in zip(group, subgroup, matrice):\n",
    "#     print(matrice)\n",
    "#     path= matrice+'.pkl'\n",
    "#     infile = open(path,'rb')\n",
    "#     df = pickle.load(infile)\n",
    "#     infile.close()\n",
    "\n",
    "#     dataset = df[df.columns[df.columns.isin(feature_cols)]]\n",
    "#     y = dataset['Erfolg']\n",
    "#     X = dataset.drop(columns=['Erfolg'])\n",
    "#     X_dup = X.drop_duplicates()\n",
    "\n",
    "#     X_new = pd.concat([X_dup,trainX])\n",
    "#     X_dup2 = X_new.drop_duplicates(keep=False)   \n",
    "\n",
    "#     fails = fails.append({'group':matrice, 'group_len':len(X), 'removed_duplicates':len(X_dup), 'merge_with_train':len(X_new), 'remove_duplicates':len(X_dup2), 'exploited_rows':len(X_new)-len(X_dup2)}, ignore_index=True)\n",
    "\n",
    "# fails.to_excel('fails.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infile = open('../04_predictionUserHistory/02_decisionTree/X_train_3months.pkl', 'rb')\n",
    "# trainX = pickle.load(infile)\n",
    "# infile.close()\n",
    "\n",
    "# infile = open('../04_predictionUserHistory/02_decisionTree/y_train_3months.pkl', 'rb')\n",
    "# trainY = pickle.load(infile)\n",
    "# infile.close()\n",
    "\n",
    "# train = trainX.assign(Erfolg = trainY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import feature list\n",
    "infile = open('../04_predictionUserHistory/01_data/FINALsmallSampleSet_3months_without_duplicates.pkl','rb')\n",
    "import_file = pickle.load(infile)\n",
    "infile.close()\n",
    "df = import_file\n",
    "feature_cols = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(clf,X,y):\n",
    "    pred = clf.predict(X)\n",
    "    a = accuracy_score(y,pred)\n",
    "    p = precision_score(y,pred)\n",
    "    r = recall_score(y,pred)\n",
    "    roc_auc = roc_auc_score(y,pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, pred).ravel()\n",
    "    fpr = fp/(fp+tn)\n",
    "\n",
    "    return a,p,r,roc_auc,fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list subgroups\n",
    "fair_metrics = pd.DataFrame(columns=['model', 'group', 'subgroup', 'Accuracy', 'Precision', 'Recall', 'AUC', 'FPR'])\n",
    "matrice = ['double_df_abi','double_df_keinAbi','double_df_boys','double_df_girls','double_df_deutsch','double_df_migration','double_df_buch0','double_df_buch1']\n",
    "group = ['abiEltern', 'abiEltern', 'gender', 'gender', 'erstsprache', 'erstsprache', 'buecher', 'buecher']\n",
    "subgroup = ['abi', 'keinAbi', 'boys', 'girls', 'deutsch', 'migration', 'buch0', 'buch1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECISION TREE\n",
    "DTE_model = pickle.load(open('../04_predictionUserHistory/02_decisionTree/DecisionTreemodel_3months.pkl', 'rb'))\n",
    "\n",
    "for (group, subgroup, matrice) in zip(group, subgroup, matrice):\n",
    "    print(matrice)\n",
    "    path= matrice+'.pkl'\n",
    "    infile = open(path,'rb')\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "    dataset= df[df.columns[df.columns.isin(feature_cols)]]\n",
    "    #X_new = X.loc[~X.set_index(list(X.columns)).index.isin(trainX.set_index(list(trainX.columns)).index)]\n",
    "\n",
    "    y = dataset['Erfolg']\n",
    "    X = dataset.drop(columns=['Erfolg'])\n",
    "    a,p,r,roc_auc,fpr = get_metrics(DTE_model,X,y)\n",
    "    fair_metrics = fair_metrics.append({'model':'DTE','group':group,'subgroup':subgroup,'Accuracy':a,'Precision': p, 'Recall':r, 'AUC':roc_auc, 'FPR':fpr}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(metrics)\n",
    "fair_metrics.to_excel('dte_metrics.xlsx')\n",
    "fair_metrics.to_pickle('dte_metrics.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "logreg_model = pickle.load(open('../04_predictionUserHistory/03_logisticRegression/Logregmodel_3months.pkl', 'rb'))\n",
    "\n",
    "for (group, subgroup, matrice) in zip(group, subgroup, matrice):\n",
    "    path= matrice+'.pkl'\n",
    "    infile = open(path,'rb')\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "    dataset = df[df.columns[df.columns.isin(feature_cols)]]\n",
    "    y = dataset['Erfolg']\n",
    "    X = dataset.drop(columns=['Erfolg'])\n",
    "\n",
    "    a,p,r,roc_auc,fpr = get_metrics(logreg_model,X,y)\n",
    "    fair_metrics = fair_metrics.append({'model':'LogReg','group':group,'subgroup':subgroup,'Accuracy':a,'Precision': p, 'Recall':r, 'AUC':roc_auc, 'FPR':fpr}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(metrics)\n",
    "fair_metrics.to_excel('log_metrics.xlsx')\n",
    "fair_metrics.to_pickle('log_metrics.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "svm_model = pickle.load(open('../04_predictionUserHistory/04_svm/SVMmodel_3months.pkl', 'rb'))\n",
    "\n",
    "for (group, subgroup, matrice) in zip(group, subgroup, matrice):\n",
    "    path= matrice+'.pkl'\n",
    "    infile = open(path,'rb')\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "    dataset = df[df.columns[df.columns.isin(feature_cols)]]\n",
    "    y = dataset['Erfolg']\n",
    "    X = dataset.drop(columns=['Erfolg'])\n",
    "\n",
    "    a,p,r,roc_auc,fpr = get_metrics(svm_model,X,y)\n",
    "    fair_metrics = fair_metrics.append({'model':'SVM','group':group,'subgroup':subgroup,'Accuracy':a,'Precision': p, 'Recall':r, 'AUC':roc_auc, 'FPR':fpr}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(metrics)\n",
    "fair_metrics.to_excel('svm_metrics.xlsx')\n",
    "fair_metrics.to_pickle('svm_metrics.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN\n",
    "nn_model = load_model('../04_predictionUserHistory/05_nn/nn_3months/')\n",
    "\n",
    "def get_dn_metrics(model, X,y):\n",
    "    X = np.asarray(X).astype('float32')\n",
    "    yhat_probs = model.predict(X, verbose=0)\n",
    "    yhat_classes =  (model.predict(X) > 0.5).astype(\"int32\")\n",
    "    # reduce to 1d array\n",
    "    yhat_probs = yhat_probs[:, 0]\n",
    "    yhat_classes = yhat_classes[:, 0]\n",
    "    a = accuracy_score(y, yhat_classes)\n",
    "    p = precision_score(y, yhat_classes)\n",
    "    r = recall_score(y, yhat_classes)\n",
    "    roc_auc = roc_auc_score(y, yhat_probs)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, yhat_classes).ravel()\n",
    "    fpr = fp/(fp+tn)\n",
    "\n",
    "    return a,p,r,roc_auc,fpr\n",
    "\n",
    "for (group, subgroup, matrice) in zip(group, subgroup, matrice):\n",
    "    path= matrice+'.pkl'\n",
    "    infile = open(path,'rb')\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "    dataset = df[df.columns[df.columns.isin(feature_cols)]]\n",
    "    y = dataset['Erfolg']\n",
    "    X = dataset.drop(columns=['Erfolg'])\n",
    "\n",
    "    a,p,r,roc_auc,fpr = get_dn_metrics(nn_model,X,y)\n",
    "    fair_metrics = fair_metrics.append({'model':'NN','group':group,'subgroup':subgroup,'Accuracy':a,'Precision': p, 'Recall':r, 'AUC':roc_auc, 'FPR':fpr}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(metrics)\n",
    "fair_metrics.to_excel('nn_metrics.xlsx')\n",
    "fair_metrics.to_pickle('nn_metrics.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
