{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, roc_auc_score, recall_score, precision_score, accuracy_score, plot_roc_curve, plot_confusion_matrix, roc_curve, confusion_matrix\n",
    "import itertools\n",
    "from tensorflow.keras.initializers import Constant, TruncatedNormal\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numpy import mean, absolute\n",
    "\n",
    "# Oversampling and under sampling\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance Out Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('../01_prognosemodell/06_newtry/fairness_ready.pkl','rb')\n",
    "df = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "df_demo = df[['UebungsID','AbiEltern']]\n",
    "df_demo = df_demo.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60]\n",
    "\n",
    "for i in n:\n",
    "    path='../01_prognosemodell/06_newtry/matrices_allsessions/matrix'+str(i)+'.pkl'\n",
    "    infile = open(path,'rb')\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "    df = df.reset_index(level=0)\n",
    "    df = pd.merge(df, df_demo, how='left', on='UebungsID')\n",
    "\n",
    "    df.AbiEltern = df.AbiEltern.astype('float')\n",
    "    df['AbiEltern'] = df['AbiEltern'].replace([2],1)\n",
    "    \n",
    "    ## Undersampling\n",
    "    df_1 = df[df.AbiEltern==1]\n",
    "    df_0 = df[df.AbiEltern==0]\n",
    "    # if(len(df_1) > len(df_0)):\n",
    "    #     n = len(df_0)\n",
    "    #     df_1 = df_1.sample(n=n)\n",
    "    # else:\n",
    "    #     n = len(df_1)\n",
    "    #     df_0 = df_0.sample(n=n)\n",
    "    df = pd.concat([df_0,df_1])    \n",
    "\n",
    "    # Randomly over sample the minority class\n",
    "    X_df = df.drop(columns=['AbiEltern'])\n",
    "    y_df = df.AbiEltern\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote= smote.fit_resample(X_df, y_df)\n",
    "    df = X_train_smote.join(pd.DataFrame(list(y_train_smote.values), columns=['AbiEltern']))\n",
    "    \n",
    "    path = 'AbiEltern_allsessions/matrix'+ str(i) +'.pkl'\n",
    "    df.to_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60]\n",
    "sentence_len= pd.DataFrame(columns=['Sentence', 'Count'])\n",
    "\n",
    "for x in n:\n",
    "    path='AbiEltern_allsessions/matrix'+str(x)+'.pkl'\n",
    "    infile = open(path,'rb')\n",
    "    get_length = pickle.load(infile)\n",
    "    infile.close()\n",
    "    l = len(get_length)\n",
    "    sentence_len = sentence_len.append({'Sentence': x, 'Count':l}, ignore_index=True)\n",
    "\n",
    "sentence_len['Sentence']=sentence_len['Sentence'].astype('int')\n",
    "sentence_len['Count']=sentence_len['Count'].astype('int')\n",
    "sns.lineplot(data=sentence_len, x=\"Sentence\", y=\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(columns=['model', 'group', 'subgroup','Length', 'Sentence', 'Accuracy', 'Precision', 'Recall', 'AUC', 'FPR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(clf,X,y,cv,pred):\n",
    "    a = accuracy_score(y,pred)\n",
    "    p = precision_score(y,pred)\n",
    "    r = recall_score(y,pred)\n",
    "    roc_auc = roc_auc_score(y,pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, pred).ravel()\n",
    "    fpr = fp/(fp+tn)\n",
    "\n",
    "    return a,p,r,roc_auc,fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60]\n",
    "feature_cols = ['Erstloesung','Schussel','Erfolg', 'Schwierigkeit', 'ist_Schulzeit', 'MehrfachFalsch', 'vorher_abgebrochen','Fehler', 'Klassenstufe', 'Jahredabei', 'AnzahlAufgaben', 'Sex__m', 'Sex__w', 'Testposition__pruefung', 'Testposition__training','Testposition__version', 'Art__GK', 'Art__GR', 'Art__GZ', 'Art__K', 'Art__LB','UserAttribut', 'OrderNumber', 'steps']\n",
    "\n",
    "for i in n:\n",
    "    #build models\n",
    "    path='AbiEltern_allsessions/matrix'+str(i)+'.pkl'\n",
    "    infile = open(path,'rb')\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "    df=df.reset_index()\n",
    "    X = df[feature_cols]\n",
    "    y = df.y\n",
    "    y= y.astype('int')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "    k = 5\n",
    "    cv = KFold(n_splits=k, random_state=None)\n",
    "\n",
    "    #DTE\n",
    "    clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5)\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "\n",
    "    a,p,r,roc_auc,fpr = get_metrics(clf,X_test,y_test,cv,pred)\n",
    "\n",
    "    metrics = metrics.append({'model':'DTE','group':'all','subgroup':'all','Length':len(df),'Sentence': i, 'Accuracy':a,'Precision': p, 'Recall':r, 'AUC':roc_auc, 'FPR':fpr}, ignore_index=True)\n",
    "\n",
    "    group = ['abiEltern', 'abiEltern']\n",
    "    subgroup = ['abi', 'keinAbi']\n",
    "    matrice = ['matrices_forte_abi', 'matrices_forte_keinAbi']\n",
    "\n",
    "    for (group, subgroup, matrix) in zip(group, subgroup, matrice):\n",
    "        path= '../01_prognosemodell/06_newtry/'+matrix+'/matrix'+str(i)+'.pkl'\n",
    "        infile = open(path,'rb')\n",
    "        df = pickle.load(infile)\n",
    "        infile.close()\n",
    "        df=df.reset_index()\n",
    "        X = df[feature_cols]\n",
    "        y = df.y\n",
    "        y= y.astype('int')\n",
    "        pred = clf.predict(X)\n",
    "        \n",
    "        a,p,r,roc_auc,fpr = get_metrics(clf,X,y,cv,pred)\n",
    "        metrics = metrics.append({'model':'DTE','group':group,'subgroup':subgroup,'Length':len(df),'Sentence': i, 'Accuracy':a,'Precision': p, 'Recall':r, 'AUC':roc_auc, 'FPR':fpr}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n =  [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60]\n",
    "feature_cols = ['Erstloesung','Schussel','Erfolg', 'Schwierigkeit', 'ist_Schulzeit', 'MehrfachFalsch', 'vorher_abgebrochen','Fehler', 'Klassenstufe', 'Jahredabei', 'AnzahlAufgaben', 'Sex__m', 'Sex__w', 'Testposition__pruefung', 'Testposition__training','Testposition__version', 'Art__GK', 'Art__GR', 'Art__GZ', 'Art__K', 'Art__LB','UserAttribut', 'OrderNumber', 'steps']\n",
    "\n",
    "for i in n:\n",
    "    #build models\n",
    "    path='AbiEltern_allsessions/matrix'+str(i)+'.pkl'\n",
    "    infile = open(path,'rb')\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "    df=df.reset_index()\n",
    "    X = df[feature_cols]\n",
    "    y = df.y\n",
    "    y= y.astype('int')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "    k = 5\n",
    "    cv = KFold(n_splits=k, random_state=None)\n",
    "\n",
    "    #knn\n",
    "    knn = KNeighborsClassifier(n_neighbors=15)##geÃ¤ndert zum test\n",
    "    knn = knn.fit(X_train, y_train)\n",
    "\n",
    "    pred = knn.predict(X_test)\n",
    "    a,p,r,roc_auc,fpr = get_metrics(knn,X_test,y_test,cv,pred)\n",
    "    metrics = metrics.append({'model':'KNN','group':'all','subgroup':'all','Length':len(df),'Sentence': i, 'Accuracy':a,'Precision': p, 'Recall':r, 'AUC':roc_auc, 'FPR':fpr}, ignore_index=True)\n",
    "\n",
    "    group = ['abiEltern', 'abiEltern']\n",
    "    subgroup = ['abi', 'keinAbi']\n",
    "    matrice = ['matrices_forte_abi', 'matrices_forte_keinAbi']\n",
    "    \n",
    "    for (group, subgroup, matrix) in zip(group, subgroup, matrice):\n",
    "        path= '../01_prognosemodell/06_newtry/'+matrix+'/matrix'+str(i)+'.pkl'\n",
    "        infile = open(path,'rb')\n",
    "        df = pickle.load(infile)\n",
    "        infile.close()\n",
    "        df=df.reset_index()\n",
    "        X = df[feature_cols]\n",
    "        y = df.y\n",
    "        y= y.astype('int')\n",
    "        pred = knn.predict(X)\n",
    "\n",
    "        a,p,r,roc_auc,fpr = get_metrics(knn,X,y,cv,pred)\n",
    "        metrics = metrics.append({'model':'KNN','group':group,'subgroup':subgroup,'Length':len(df),'Sentence': i, 'Accuracy':a,'Precision': p, 'Recall':r, 'AUC':roc_auc, 'FPR':fpr}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model\n",
    "def build_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(24, input_dim=24, activation='relu'))\n",
    "\tmodel.add(Dense(48, activation='relu'))\n",
    "\tmodel.add(Dense(24, activation='relu'))\n",
    "\tmodel.add(Dense(12, activation='relu'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t\t\n",
    "\treturn model\n",
    "\n",
    "\n",
    "def get_dn_metrics(model, X,y):\n",
    "    yhat_probs = model.predict(X, verbose=0)\n",
    "    yhat_classes =  (model.predict(X) > 0.5).astype(\"int32\")\n",
    "    # reduce to 1d array\n",
    "    yhat_probs = yhat_probs[:, 0]\n",
    "    yhat_classes = yhat_classes[:, 0]\n",
    "    a = accuracy_score(y, yhat_classes)\n",
    "    p = precision_score(y, yhat_classes)\n",
    "    r = recall_score(y, yhat_classes)\n",
    "    roc_auc = roc_auc_score(y, yhat_probs)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, yhat_classes).ravel()\n",
    "    fpr = fp/(fp+tn)\n",
    "\n",
    "    return a,p,r,roc_auc,fpr\n",
    "\n",
    "n =  [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60]\n",
    "feature_cols = ['Erstloesung','Schussel','Erfolg', 'Schwierigkeit', 'ist_Schulzeit', 'MehrfachFalsch', 'vorher_abgebrochen','Fehler', 'Klassenstufe', 'Jahredabei', 'AnzahlAufgaben', 'Sex__m', 'Sex__w', 'Testposition__pruefung', 'Testposition__training','Testposition__version', 'Art__GK', 'Art__GR', 'Art__GZ', 'Art__K', 'Art__LB','UserAttribut', 'OrderNumber', 'steps']\n",
    "\n",
    "for i in n:\n",
    "    path='AbiEltern_allsessions/matrix'+str(i)+'.pkl'\n",
    "    infile = open(path,'rb')\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "    df=df.reset_index()\n",
    "\n",
    "    y_len = len(feature_cols)\n",
    "    X = df[feature_cols].astype(float)\n",
    "    y = df.y\n",
    "    y= y.astype('int')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "    model = build_model()\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer='Adam',\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        epochs=10,\n",
    "        batch_size=128,\n",
    "        verbose=0,\n",
    "        validation_data=(X_test, y_test)\n",
    "    )\n",
    "\n",
    "    scores = model.evaluate(\n",
    "        x=X_test,\n",
    "        y=y_test,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    a,p,r,roc_auc,fpr= get_dn_metrics(model, X_test,y_test)\n",
    "    metrics = metrics.append({'model':'DL','group':'all','subgroup':'all','Length':len(df),'Sentence': i, 'Accuracy':a,'Precision': p, 'Recall':r, 'AUC':roc_auc, 'FPR':fpr}, ignore_index=True)\n",
    "\n",
    "    group = ['abiEltern', 'abiEltern']\n",
    "    subgroup = ['abi', 'keinAbi']\n",
    "    matrice = ['matrices_forte_abi', 'matrices_forte_keinAbi']\n",
    "\n",
    "    for (group, subgroup, matrix) in zip(group, subgroup, matrice):\n",
    "        path= '../01_prognosemodell/06_newtry/'+matrix+'/matrix'+str(i)+'.pkl'\n",
    "        infile = open(path,'rb')\n",
    "        df = pickle.load(infile)\n",
    "        infile.close()\n",
    "        df=df.reset_index()\n",
    "        y_len = len(feature_cols)\n",
    "        X = df[feature_cols].astype(float)\n",
    "        y = df.y\n",
    "        y= y.astype('int')\n",
    "\n",
    "        a,p,r,roc_auc,fpr= get_dn_metrics(model, X,y)\n",
    "\n",
    "        metrics = metrics.append({'model':'DL','group':group,'subgroup':subgroup,'Length':len(df),'Sentence': i, 'Accuracy':a,'Precision': p, 'Recall':r, 'AUC':roc_auc, 'FPR':fpr}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = metrics.groupby(metrics.group)\n",
    "df_all = grouped.get_group(\"all\")\n",
    "modell = df_all.groupby(df_all.model)\n",
    "dte = modell.get_group(\"DTE\")\n",
    "knn = modell.get_group(\"KNN\")\n",
    "dl = modell.get_group(\"DL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data=df_all, x='Sentence', y='Accuracy', hue='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data=df_all, x='Sentence', y='Length', hue='model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = metrics\n",
    "grouped = df.groupby(df.group)\n",
    "df_abiEltern = grouped.get_group(\"abiEltern\")\n",
    "\n",
    "df_abiEltern = df_abiEltern.drop(columns=['group', 'Accuracy'])\n",
    "df_abiEltern = pd.pivot_table(df_abiEltern, values=[\"Precision\",\"Recall\",\"AUC\",\"FPR\"], index=[\"model\", \"Sentence\"], columns=[\"subgroup\"])\n",
    "df_abiEltern['PP'] = df_abiEltern.Precision.abi-df_abiEltern.Precision.keinAbi\n",
    "df_abiEltern['EO'] = df_abiEltern.Recall.keinAbi-df_abiEltern.Recall.abi\n",
    "df_abiEltern['SA'] = df_abiEltern.AUC.abi-df_abiEltern.AUC.keinAbi\n",
    "df_abiEltern['PE'] = df_abiEltern.FPR.keinAbi-df_abiEltern.FPR.abi\n",
    "df_abiEltern = df_abiEltern.drop(columns=['AUC','Precision','Recall','FPR'])\n",
    "df_abiEltern.columns = df_abiEltern.columns.droplevel(1)\n",
    "df_abiEltern = pd.pivot_table(df_abiEltern, values=[\"PP\",\"EO\",\"SA\",\"PE\"], index=[\"Sentence\"], columns=[\"model\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format result\n",
    "\n",
    "def threshold001(v, props=''):\n",
    "    return props if (v > 0.02) or (v < -0.02) else None\n",
    "\n",
    "def threshold005(v, props=''):\n",
    "    return props if (v > 0.05) or (v < -0.05) else None\n",
    "\n",
    "def negativeValue(v, props=''):\n",
    "    return props if (v < 0) else None\n",
    "\n",
    "def showTable(df):\n",
    "    styled = df.style.set_properties(color=\"black\", align=\"right\")\\\n",
    "        .set_properties(**{'background-color': 'white'})\\\n",
    "        .applymap(threshold001, props='color:orange;')\\\n",
    "        .applymap(threshold005, props='color:red;')\\\n",
    "        .applymap(negativeValue, props='font-weight:bold;')\n",
    "    return styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_abiEltern\n",
    "met = ['EO','PE','PP','SA']\n",
    "fertig = pd.DataFrame()\n",
    "for x in met:        \n",
    "    a = 0\n",
    "    for i in range(2, 10):\n",
    "        a = a+test[x].DL[i]\n",
    "    a = a/8\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Metrik':[x],\n",
    "            'Model': 'DL',\n",
    "            'Range': '02-9',\n",
    "            'Val': a\n",
    "        }\n",
    "    )\n",
    "    fertig = pd.concat([fertig, temp])\n",
    "\n",
    "    b = 0\n",
    "    for i in range(10, 20):\n",
    "        b = b+test[x].DL[i]\n",
    "    b = b/9\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Metrik':[x],\n",
    "            'Model': 'DL',\n",
    "            'Range': '10-19',\n",
    "            'Val': b\n",
    "        }\n",
    "    )\n",
    "    fertig = pd.concat([fertig, temp])\n",
    "\n",
    "    c = 0\n",
    "    for i in range(20, 30):\n",
    "        c = c+test[x].DL[i]\n",
    "    c = c/9\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Metrik':[x],\n",
    "            'Model': 'DL',\n",
    "            'Range': '20-29',\n",
    "            'Val': c\n",
    "        }\n",
    "    )\n",
    "    fertig = pd.concat([fertig, temp])\n",
    "\n",
    "    d = 0\n",
    "    for i in range(30, 40):\n",
    "        d = d+test[x].DL[i]\n",
    "    d = d/9\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Metrik':[x],\n",
    "            'Model': 'DL',\n",
    "            'Range': '30-39',\n",
    "            'Val': d\n",
    "        }\n",
    "    )\n",
    "    fertig = pd.concat([fertig, temp])\n",
    "\n",
    "    e = 0\n",
    "    for i in range(40, 50):\n",
    "        e = e+test[x].DL[i]\n",
    "    e = e/9\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Metrik':[x],\n",
    "            'Model': 'DL',\n",
    "            'Range': '40-49',\n",
    "            'Val': e\n",
    "        }\n",
    "    )\n",
    "    fertig = pd.concat([fertig, temp])\n",
    "\n",
    "    f = 0\n",
    "    for i in range(50, 60):\n",
    "        f = f+test[x].DL[i]\n",
    "    f = f/10\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Metrik':[x],\n",
    "            'Model': 'DL',\n",
    "            'Range': '50-60',\n",
    "            'Val': f\n",
    "        }\n",
    "    )\n",
    "    fertig = pd.concat([fertig, temp])\n",
    "\n",
    "    \n",
    "\n",
    "met = ['EO','PE','PP','SA']\n",
    "for x in met:        \n",
    "    a = 0\n",
    "    for i in range(2, 10):\n",
    "        a = a+test[x].DTE[i]\n",
    "    a = a/8\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Metrik':[x],\n",
    "            'Model': 'DTE',\n",
    "            'Range': '02-9',\n",
    "            'Val': a\n",
    "        }\n",
    "    )\n",
    "    fertig = pd.concat([fertig, temp])\n",
    "\n",
    "    b = 0\n",
    "    for i in range(10, 20):\n",
    "        b = b+test[x].DTE[i]\n",
    "    b = b/9\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Metrik':[x],\n",
    "            'Model': 'DTE',\n",
    "            'Range': '10-19',\n",
    "            'Val': b\n",
    "        }\n",
    "    )\n",
    "    fertig = pd.concat([fertig, temp])\n",
    "\n",
    "    c = 0\n",
    "    for i in range(20, 30):\n",
    "        c = c+test[x].DTE[i]\n",
    "    c = c/9\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Metrik':[x],\n",
    "            'Model': 'DTE',\n",
    "            'Range': '20-29',\n",
    "            'Val': c\n",
    "        }\n",
    "    )\n",
    "    fertig = pd.concat([fertig, temp])\n",
    "\n",
    "    d = 0\n",
    "    for i in range(30, 40):\n",
    "        d = d+test[x].DTE[i]\n",
    "    d = d/9\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Metrik':[x],\n",
    "            'Model': 'DTE',\n",
    "            'Range': '30-39',\n",
    "            'Val': d\n",
    "        }\n",
    "    )\n",
    "    fertig = pd.concat([fertig, temp])\n",
    "\n",
    "    e = 0\n",
    "    for i in range(40, 50):\n",
    "        e = e+test[x].DTE[i]\n",
    "    e = e/9\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Metrik':[x],\n",
    "            'Model': 'DTE',\n",
    "            'Range': '40-49',\n",
    "            'Val': e\n",
    "        }\n",
    "    )\n",
    "    fertig = pd.concat([fertig, temp])\n",
    "\n",
    "    f = 0\n",
    "    for i in range(50, 60):\n",
    "        f = f+test[x].DTE[i]\n",
    "    f = f/10\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Metrik':[x],\n",
    "            'Model': 'DTE',\n",
    "            'Range': '50-60',\n",
    "            'Val': f\n",
    "        }\n",
    "    )\n",
    "    fertig = pd.concat([fertig, temp])\n",
    "\n",
    "met = ['EO','PE','PP','SA']\n",
    "for x in met:        \n",
    "    a = 0\n",
    "    for i in range(2, 10):\n",
    "        a = a+test[x].KNN[i]\n",
    "    a = a/8\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Metrik':[x],\n",
    "            'Model': 'KNN',\n",
    "            'Range': '02-9',\n",
    "            'Val': a\n",
    "        }\n",
    "    )\n",
    "    fertig = pd.concat([fertig, temp])\n",
    "\n",
    "    b = 0\n",
    "    for i in range(10, 20):\n",
    "        b = b+test[x].KNN[i]\n",
    "    b = b/9\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Metrik':[x],\n",
    "            'Model': 'KNN',\n",
    "            'Range': '10-19',\n",
    "            'Val': b\n",
    "        }\n",
    "    )\n",
    "    fertig = pd.concat([fertig, temp])\n",
    "\n",
    "    c = 0\n",
    "    for i in range(20, 30):\n",
    "        c = c+test[x].KNN[i]\n",
    "    c = c/9\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Metrik':[x],\n",
    "            'Model': 'KNN',\n",
    "            'Range': '20-29',\n",
    "            'Val': c\n",
    "        }\n",
    "    )\n",
    "    fertig = pd.concat([fertig, temp])\n",
    "\n",
    "    d = 0\n",
    "    for i in range(30, 40):\n",
    "        d = d+test[x].KNN[i]\n",
    "    d = d/9\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Metrik':[x],\n",
    "            'Model': 'KNN',\n",
    "            'Range': '30-39',\n",
    "            'Val': d\n",
    "        }\n",
    "    )\n",
    "    fertig = pd.concat([fertig, temp])\n",
    "\n",
    "    e = 0\n",
    "    for i in range(40, 50):\n",
    "        e = e+test[x].KNN[i]\n",
    "    e = e/9\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Metrik':[x],\n",
    "            'Model': 'KNN',\n",
    "            'Range': '40-49',\n",
    "            'Val': e\n",
    "        }\n",
    "    )\n",
    "    fertig = pd.concat([fertig, temp])\n",
    "\n",
    "    f = 0\n",
    "    for i in range(50, 60):\n",
    "        f = f+test[x].KNN[i]\n",
    "    f = f/10\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Metrik':[x],\n",
    "            'Model': 'KNN',\n",
    "            'Range': '50-60',\n",
    "            'Val': f\n",
    "        }\n",
    "    )\n",
    "    fertig = pd.concat([fertig, temp])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_table = pd.pivot_table(fertig, values=['Val'], index=['Range'], columns=['Metrik','Model'])\n",
    "showTable(mean_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer = pd.ExcelWriter('df_abiEltern.xlsx', engine='xlsxwriter')\n",
    "# df_abiEltern.to_excel(writer, sheet_name='AbiEltern')\n",
    "# writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
